{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "import logging\n",
    "import os\n",
    "import re\n",
    "import typing as t\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from jinja2 import Template\n",
    "from openai import OpenAI\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "# Openrouter constants\n",
    "OPENROUTER_API_KEY = os.getenv(\"OPENROUTER_API_KEY\")\n",
    "OPENTROUTER_BASE_URL = 'https://openrouter.ai/api/v1'\n",
    "\n",
    "\n",
    "# Experiment constants\n",
    "EXPERIMENT_NAME = 'exp1.0'  # baseline\n",
    "MODEL_NAME = 'openai/gpt-4o-mini'\n",
    "TEMPERATURE = 0.0\n",
    "\n",
    "RANDOM_SEED = 20250402\n",
    "\n",
    "N_ARMS = 5\n",
    "DELTA = 0.2\n",
    "N_TRIALS = 3\n",
    "\n",
    "\n",
    "ARM_NAME_TO_IDX = {'blue': 0, 'green': 1, 'red': 2, 'yellow': 3, 'purple': 4}\n",
    "ARM_IDX_TO_NAME = {v: k for k, v in ARM_NAME_TO_IDX.items()}\n",
    "\n",
    "\n",
    "def bootstrap() -> None:\n",
    "    # logging.basicConfig(format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "    np.random.seed(RANDOM_SEED)\n",
    "\n",
    "\n",
    "bootstrap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT_TEMPLATE = \"\"\"\\\n",
    "You are a bandit algorithm in a room with {{n_arms}} buttons labeled blue, green, red, yellow, purple. \\\n",
    "Each button is associated with a Bernoulli distribution with a fixed but unknown mean; the means \\\n",
    "for the buttons could be different. For each button, when you press it, you will get a reward \\\n",
    "that is sampled from the button's associated distribution. You have {{n_trials}} time steps and, on each \\\n",
    "time step, you can choose any button and receive the reward. Your goal is to maximize the total \\\n",
    "reward over the {{n_trials}} time steps.\n",
    "\n",
    "At each time step, I will show you a summary of your past choices and rewards. Then you must \\\n",
    "make the next choice, which must be exactly one of blue, green, red, yellow, purple. Let's think \\\n",
    "step by step to make sure we make a good choice. You must provide your final answer within the \\\n",
    "tags <Answer>COLOR</Answer> where COLOR is one of blue, green, red, yellow, purple.\n",
    "\"\"\"\n",
    "SYSTEM_PROMPT_TEMPLATE = Template(SYSTEM_PROMPT_TEMPLATE)\n",
    "\n",
    "\n",
    "USER_PROMPT_TEMLATE = \"\"\"\\\n",
    "So far you have played {{n_trials}} times with your past choices and rewards summarized\n",
    "as follows:\n",
    "- blue button: pressed {{blue_n_occur}} times. Reward: {{blue_good_occur}} times gave good outcomes and {{blue_bad_occur}} times gave bad outcomes \n",
    "- green button: pressed {{green_n_occur}} times. Reward: {{green_good_occur}} times gave good outcomes and {{green_bad_occur}} times gave bad outcomes \n",
    "- red button: pressed {{red_n_occur}} times. Reward:{{red_good_occur}} times gave good outcomes and {{red_bad_occur}} times gave bad outcomes\n",
    "- yellow button: pressed {{yellow_n_occur}} times. Reward:{{yellow_good_occur}} times gave good outcomes and {{yellow_bad_occur}} times gave bad outcomes\n",
    "- purple button: pressed {{purple_n_occur}} times. Reward:{{purple_good_occur}} times gave good outcomes and {{purple_bad_occur}} times gave bad outcomes\n",
    "\n",
    "Which button will you choose next? Remember, YOU MUST provide your final answer within the tags \\\n",
    "<Answer>COLOR</Answer> where COLOR is one of blue, green, red, yellow, purple. Let's think step \\\n",
    "by step to make sure we make a good choice.\n",
    "\"\"\"\n",
    "USER_PROMPT_TEMLATE = Template(USER_PROMPT_TEMLATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "So far you have played 10 times with your past choices and rewards summarized\n",
      "as follows:\n",
      "- blue button: pressed 4 times. Reward: 1 times gave good outcomes and 2 times gave bad outcomes \n",
      "- green button: pressed 0 times. Reward:  times gave good outcomes and  times gave bad outcomes \n",
      "- red button: pressed 3 times. Reward: times gave good outcomes and  times gave bad outcomes\n",
      "- yellow button: pressed 0 times. Reward: times gave good outcomes and  times gave bad outcomes\n",
      "- purple button: pressed 3 times. Reward: times gave good outcomes and  times gave bad outcomes\n",
      "\n",
      "Which button will you choose next? Remember, YOU MUST provide your final answer within the tags <Answer>COLOR</Answer> where COLOR is one of blue, green, red, yellow, purple. Let's think step by step to make sure we make a good choice.\n"
     ]
    }
   ],
   "source": [
    "# Rendering example\n",
    "example_prompt_inputs = {\n",
    "    'n_trials': 10,\n",
    "    'blue_n_occur': 4,\n",
    "    'blue_good_occur':1,\n",
    "    \"blue_bad_occur\":2,\n",
    "    'blue_avg_reward': 0.4,\n",
    "    'green_n_occur': 0,\n",
    "    'green_avg_reward': 0,\n",
    "    'red_n_occur': 3,\n",
    "    'red_avg_reward': 0.1,\n",
    "    'yellow_n_occur': 0,\n",
    "    'yellow_avg_reward': 0,\n",
    "    'purple_n_occur': 3,\n",
    "    'purple_avg_reward': 0.2\n",
    "}\n",
    "print(USER_PROMPT_TEMLATE.render(**example_prompt_inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiArmedBandit:\n",
    "    def __init__(self, n_arms: int, delta: float) -> None:\n",
    "        self.n_arms = n_arms\n",
    "        self.delta = delta\n",
    "\n",
    "        means = [0.5 + self.delta / 2] + [0.5 - self.delta / 2] * (self.n_arms - 1)\n",
    "        np.random.shuffle(means)\n",
    "\n",
    "        self.means = means\n",
    "        self.best_arm = np.argmax(means)\n",
    "\n",
    "    def pull(self, arm: int) -> int:\n",
    "        assert 0 <= arm < self.n_arms, f\"Arm {arm} doesn't exist\"\n",
    "\n",
    "        p = self.means[arm]\n",
    "        reward = np.random.binomial(1, p=p)\n",
    "        \n",
    "        return reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_client() -> OpenAI:\n",
    "    client = OpenAI(\n",
    "        base_url=OPENTROUTER_BASE_URL,\n",
    "        api_key=OPENROUTER_API_KEY,\n",
    "    )\n",
    "    return client\n",
    "\n",
    "\n",
    "def get_prediction(client: OpenAI, system_prompt: str, user_prompt: str, **kwargs) -> str | None:\n",
    "    messages = [\n",
    "        {\n",
    "            'role': 'system',\n",
    "            'content': system_prompt\n",
    "        },\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': user_prompt\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    prediction = None\n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "            model=MODEL_NAME,\n",
    "            messages=messages,\n",
    "            temperature=TEMPERATURE,\n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "        prediction = completion.choices[0].message.content\n",
    "        \n",
    "    except Exception as _:\n",
    "        logging.warning('Request failed')\n",
    " \n",
    "    return prediction\n",
    "\n",
    "\n",
    "def build_prompt_inputs(trial: int, rewards: t.Dict[str, int], occurrences: t.Dict[str, int]) -> t.Dict[str, float]:\n",
    "    \n",
    "    prompt_inputs = {\n",
    "        'n_trials': trial,\n",
    "\n",
    "        'blue_n_occur': occurrences['blue'][\"count\"],\n",
    "        \"blue_good_occur\": occurrences[\"blue\"][\"Good\"],\n",
    "        \"blue_bad_occur\": occurrences[\"blue\"][\"Bad\"],\n",
    "\n",
    "        'red_n_occur': occurrences['red'][\"count\"],\n",
    "        \"red_good_occur\": occurrences[\"red\"][\"Good\"],\n",
    "        \"red_bad_occur\": occurrences[\"red\"][\"Bad\"],\n",
    "\n",
    "        'green_n_occur': occurrences['green'][\"count\"],\n",
    "        \"green_good_occur\": occurrences[\"green\"][\"Good\"],\n",
    "        \"green_bad_occur\": occurrences[\"green\"][\"Bad\"],\n",
    "\n",
    "        'yellow_n_occur': occurrences['yellow'][\"count\"],\n",
    "        \"yellow_good_occur\": occurrences[\"yellow\"][\"Good\"],\n",
    "        \"yellow_bad_occur\": occurrences[\"yellow\"][\"Bad\"],\n",
    "\n",
    "        'purple_n_occur': occurrences['purple'][\"count\"],\n",
    "        \"purple_good_occur\": occurrences[\"purple\"][\"Good\"],\n",
    "        \"purple_bad_occur\": occurrences[\"purple\"][\"Bad\"],\n",
    "    }\n",
    "\n",
    "    return prompt_inputs\n",
    "\n",
    "\n",
    "def extract_arm_color(prediction: str) -> str | None:    \n",
    "    names = '|'.join(ARM_NAME_TO_IDX.keys())\n",
    "    pattern = f'<Answer>({names})</Answer>'\n",
    "    match = re.search(pattern, prediction)\n",
    "\n",
    "    color = None\n",
    "    if match:\n",
    "        color = match.group(1)\n",
    "\n",
    "    return color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = create_client()\n",
    "bandit = MultiArmedBandit(n_arms=N_ARMS, delta=DELTA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_verbalised_reward(reward:int):\n",
    "    return \"Good\" if reward == 1 else \"Bad\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [10:13<00:00,  6.13s/it]\n"
     ]
    }
   ],
   "source": [
    "stats = []\n",
    "history = ''\n",
    "\n",
    "rewards = {k: 0 for k in ARM_NAME_TO_IDX.keys()}\n",
    "occurrences = {k: {\"count\": 0, \"Good\": 0, \"Bad\":0} for k in ARM_NAME_TO_IDX.keys()}\n",
    "for trial in tqdm(range(N_TRIALS), total=N_TRIALS):\n",
    "    system_prompt = SYSTEM_PROMPT_TEMPLATE.render({'n_arms': N_ARMS, 'n_trials': N_TRIALS})\n",
    "\n",
    "    user_prompt_inputs = build_prompt_inputs(trial, rewards, occurrences)\n",
    "    user_prompt = USER_PROMPT_TEMLATE.render(user_prompt_inputs)\n",
    "    history += f'{user_prompt}\\n'\n",
    "    prediction = get_prediction(client, system_prompt, user_prompt)\n",
    "    history += f\"{prediction}\\n\\n\"\n",
    "\n",
    "    arm_name = extract_arm_color(prediction)\n",
    "    arm_idx = ARM_NAME_TO_IDX[arm_name]\n",
    "\n",
    "    reward = bandit.pull(arm_idx)\n",
    "    reward_valence = extract_verbalised_reward(reward=reward)\n",
    "\n",
    "    occurrences[arm_name][\"count\"] += 1\n",
    "    occurrences[arm_name][reward_valence] += 1\n",
    "    rewards[arm_name] += reward\n",
    "\n",
    "    cumulative_reward = sum(rewards.values())\n",
    "    cumulative_reward_per_arm = {f'cumulative_reward_{k}': v for k, v in rewards.items()}\n",
    "    cumulative_occurrences_per_arm = {f'cumulative_occurrence_{k}': v[\"count\"] for k, v in occurrences.items()}\n",
    "    stats.append({\n",
    "        'trial': trial,\n",
    "        'arm_name': arm_name,\n",
    "        'arm_idx': arm_idx,\n",
    "        'reward': reward,\n",
    "        'cumulative_reward': cumulative_reward,\n",
    "        'system_prompt': system_prompt,\n",
    "        'user_prompt': user_prompt,\n",
    "        'raw_prediction': prediction,\n",
    "        'best_arm': ARM_IDX_TO_NAME[bandit.best_arm],\n",
    "        **cumulative_reward_per_arm,\n",
    "        **cumulative_occurrences_per_arm\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "df = pd.DataFrame(stats)\n",
    "\n",
    "DATA_DIR = Path('../data')\n",
    "EXPERIMENT_DIR = DATA_DIR / EXPERIMENT_NAME\n",
    "EXPERIMENT_DIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "model_name = MODEL_NAME.replace('/', '_').replace(':', '_').replace('-', '_')\n",
    "version = datetime.now().strftime('%Y%m%d%H%M%S')\n",
    "\n",
    "filename = f'{EXPERIMENT_NAME}_{model_name}_arms-{N_ARMS}_delta-{DELTA}_trials-{N_TRIALS}_v{version}.csv'\n",
    "filepath = EXPERIMENT_DIR / filename\n",
    "\n",
    "df.to_csv(filepath, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
