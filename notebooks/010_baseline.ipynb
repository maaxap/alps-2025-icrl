{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import re\n",
    "import typing as t\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from jinja2 import Template\n",
    "from openai import OpenAI\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "# Openrouter constants\n",
    "OPENROUTER_API_KEY = '<openrouter-api-key>'\n",
    "OPENTROUTER_BASE_URL = 'https://openrouter.ai/api/v1'\n",
    "\n",
    "\n",
    "# Experiment constants\n",
    "EXPERIMENT_NAME = 'exp1.0'  # baseline\n",
    "MODEL_NAME = 'openai/gpt-4o-mini'\n",
    "TEMPERATURE = 0.0\n",
    "\n",
    "RANDOM_SEED = 20250402\n",
    "\n",
    "N_ARMS = 5\n",
    "DELTA = 0.2\n",
    "N_TRIALS = 10\n",
    "\n",
    "\n",
    "ARM_NAME_TO_IDX = {'blue': 0, 'green': 1, 'red': 2, 'yellow': 3, 'purple': 4}\n",
    "ARM_IDX_TO_NAME = {v: k for k, v in ARM_NAME_TO_IDX.items()}\n",
    "\n",
    "\n",
    "def bootstrap() -> None:\n",
    "    logging.basicConfig(format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "    np.random.seed(RANDOM_SEED)\n",
    "\n",
    "\n",
    "bootstrap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT_TEMPLATE = \"\"\"\\\n",
    "You are in a room with 5 buttons labeled blue, green, red, yellow, purple. \\\n",
    "Each button is associated with a Bernoulli distribution with a fixed but unknown mean; \\\n",
    "the means for the buttons could be different. For each button, when you press it, you \\\n",
    "will get a reward that is sampled from the button's associated distribution. You have 10 \\\n",
    "time steps and, on each time step, you can choose any button and receive the reward. \\\n",
    "Your goal is to maximize the total reward over the 10 time steps. \\\n",
    "At each time step, I will show you your past choices and rewards. Then you must make \\\n",
    "the next choice, which must be exactly one of blue, green, red, yellow, purple. You must \\\n",
    "provide your final answer immediately within the tags <Answer>COLOR</Answer> \\\n",
    "where COLOR is one of blue, green, red, yellow, purple and with no text explanation.\n",
    "\"\"\"\n",
    "SYSTEM_PROMPT_TEMPLATE = Template(SYSTEM_PROMPT_TEMPLATE)\n",
    "\n",
    "\n",
    "USER_PROMPT_TEMLATE = \"\"\"\\\n",
    "So far you have played {{n_trials}} times with your past choices and rewards summarized\n",
    "as follows:\n",
    "- blue button: pressed {{blue_n_occur}} times {%- if blue_n_occur != 0 %} with average reward {{blue_avg_reward}}{% endif %}\n",
    "- green button: pressed {{green_n_occur}} times {%- if green_n_occur != 0 %} with average reward {{green_avg_reward}}{% endif %}\n",
    "- red button: pressed {{red_n_occur}} times {%- if red_n_occur != 0 %} with average reward {{red_avg_reward}}{% endif %}\n",
    "- yellow button: pressed {{yellow_n_occur}} times {%- if yellow_n_occur != 0 %} with average reward {{yellow_avg_reward}}{% endif %}\n",
    "- purple button: pressed {{purple_n_occur}} times {%- if purple_n_occur != 0 %} with average reward {{purple_avg_reward}}{% endif %}\n",
    "\n",
    "Which button will you choose next? Remember, YOU MUST provide your final answer\n",
    "within the tags <Answer>COLOR</Answer> where COLOR is one of blue, green,\n",
    "red, yellow, purple. Let's think step by step to make sure we make a good choice.\n",
    "\"\"\"\n",
    "USER_PROMPT_TEMLATE = Template(USER_PROMPT_TEMLATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rendering example\n",
    "example_prompt_inputs = {\n",
    "    'n_trials': 10,\n",
    "    'blue_n_occur': 4,\n",
    "    'blue_avg_reward': 0.4,\n",
    "    'green_n_occur': 0,\n",
    "    'green_avg_reward': 0,\n",
    "    'red_n_occur': 3,\n",
    "    'red_avg_reward': 0.1,\n",
    "    'yellow_n_occur': 0,\n",
    "    'yellow_avg_reward': 0,\n",
    "    'purple_n_occur': 3,\n",
    "    'purple_avg_reward': 0.2\n",
    "}\n",
    "print(USER_PROMPT_TEMLATE.render(**example_prompt_inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiArmedBandit:\n",
    "    def __init__(self, n_arms: int, delta: float) -> None:\n",
    "        self.n_arms = n_arms\n",
    "        self.delta = delta\n",
    "\n",
    "        means = [0.5 + self.delta / 2] + [0.5 - self.delta / 2] * (self.n_arms - 1)\n",
    "        np.random.shuffle(means)\n",
    "\n",
    "        self.means = means\n",
    "        self.best_arm = np.argmax(means)\n",
    "\n",
    "    def pull(self, arm: int) -> int:\n",
    "        assert 0 <= arm < self.n_arms, f\"Arm {arm} doesn't exist\"\n",
    "\n",
    "        p = self.means[arm]\n",
    "        reward = np.random.binomial(1, p=p)\n",
    "        \n",
    "        return reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_client() -> OpenAI:\n",
    "    client = OpenAI(\n",
    "        base_url=OPENTROUTER_BASE_URL,\n",
    "        api_key=OPENROUTER_API_KEY,\n",
    "    )\n",
    "    return client\n",
    "\n",
    "\n",
    "def get_prediction(client: OpenAI, system_prompt: str, user_prompt: str, **kwargs) -> str | None:\n",
    "    messages = [\n",
    "        {\n",
    "            'role': 'system',\n",
    "            'content': system_prompt\n",
    "        },\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': user_prompt\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    prediction = None\n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "            model=MODEL_NAME,\n",
    "            messages=messages,\n",
    "            temperature=TEMPERATURE,\n",
    "            **kwargs\n",
    "        )\n",
    "        prediction = completion.choices[0].message.content\n",
    "    except Exception as _:\n",
    "        logging.warning('Request failed')\n",
    " \n",
    "    return prediction\n",
    "\n",
    "\n",
    "def build_prompt_inputs(trial: int, rewards: t.Dict[str, int], occurrences: t.Dict[str, int]) -> t.Dict[str, float]:\n",
    "    def average(key: str):\n",
    "        occ = occurrences[key]\n",
    "        total = rewards[key]\n",
    "        return total / occ if occ != 0 else 0.0\n",
    "    \n",
    "    prompt_inputs = {\n",
    "        'n_trials': trial,\n",
    "\n",
    "        'blue_n_occur': occurrences['blue'],\n",
    "        'blue_avg_reward': average('blue'),\n",
    "\n",
    "        'red_n_occur': occurrences['green'],\n",
    "        'red_avg_reward': average('green'),\n",
    "\n",
    "        'green_n_occur': occurrences['red'],\n",
    "        'green_avg_reward': average('red'),\n",
    "\n",
    "        'yellow_n_occur': occurrences['yellow'],\n",
    "        'yellow_avg_reward': average('yellow'),\n",
    "\n",
    "        'purple_n_occur': occurrences['purple'],\n",
    "        'purple_avg_reward': average('purple'),\n",
    "    }\n",
    "\n",
    "    return prompt_inputs\n",
    "\n",
    "\n",
    "def extract_arm_color(prediction: str) -> str | None:    \n",
    "    names = '|'.join(ARM_NAME_TO_IDX.keys())\n",
    "    pattern = f'<Answer>({names})</Answer>'\n",
    "    match = re.search(pattern, prediction)\n",
    "\n",
    "    color = None\n",
    "    if match:\n",
    "        color = match.group(1)\n",
    "\n",
    "    return color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = create_client()\n",
    "bandit = MultiArmedBandit(n_arms=N_ARMS, delta=DELTA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = []\n",
    "\n",
    "rewards = {k: 0 for k in ARM_NAME_TO_IDX.keys()}\n",
    "occurrences = {k: 0 for k in ARM_NAME_TO_IDX.keys()}\n",
    "for trial in tqdm(range(N_TRIALS), total=N_TRIALS):\n",
    "    system_prompt = SYSTEM_PROMPT_TEMPLATE.render()\n",
    "\n",
    "    user_prompt_inputs = build_prompt_inputs(trial, rewards, occurrences)\n",
    "    user_prompt = USER_PROMPT_TEMLATE.render(user_prompt_inputs)\n",
    "    prediction = get_prediction(client, system_prompt, user_prompt)\n",
    "\n",
    "    arm_name = extract_arm_color(prediction)\n",
    "    arm_idx = ARM_NAME_TO_IDX[arm_name]\n",
    "\n",
    "    reward = bandit.pull(arm_idx)\n",
    "\n",
    "    occurrences[arm_name] += 1\n",
    "    rewards[arm_name] += reward\n",
    "\n",
    "    cumulative_reward = sum(rewards.values())\n",
    "    cumulative_reward_per_arm = {f'cumulative_reward_{k}': v for k, v in rewards.items()}\n",
    "    cumulative_occurrences_per_arm = {f'cumulative_occurrence_{k}': v for k, v in occurrences.items()}\n",
    "    stats.append({\n",
    "        'trial': trial,\n",
    "        'arm_name': arm_name,\n",
    "        'arm_idx': arm_idx,\n",
    "        'reward': reward,\n",
    "        'cumulative_reward': cumulative_reward,\n",
    "        **cumulative_reward_per_arm,\n",
    "        **cumulative_occurrences_per_arm\n",
    "    })\n",
    "    \n",
    "\n",
    "df = pd.DataFrame(stats)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
