{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import re\n",
    "import typing as t\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from jinja2 import Template\n",
    "from openai import OpenAI\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "# Openrouter constants\n",
    "COHERE_API_KEY = '8N3pZ1Qi8ByScVL3dFmYFg0KRKYClhYvpkTBVMEf'\n",
    "COHERE_BASE_URL = 'https://api.cohere.ai/compatibility/v1'\n",
    "\n",
    "\n",
    "# Experiment constants\n",
    "EXPERIMENT_NAME = 'exp4.0'\n",
    "# MODEL_NAME = 'openai/gpt-4o-mini'\n",
    "# MODEL_NAME = 'deepseek/deepseek-r1'\n",
    "MODEL_NAME = 'command-a-03-2025'\n",
    "TEMPERATURE = 0.0\n",
    "\n",
    "RANDOM_SEED = 20250402\n",
    "\n",
    "N_ARMS = 5\n",
    "DELTA = 0.2\n",
    "N_TRIALS = 100\n",
    "\n",
    "N_EXPERIMENT_RUNS = 20\n",
    "N_WORKERS = 20\n",
    "\n",
    "\n",
    "COLORS = [\n",
    "    'blue', 'red', 'green', 'yellow', 'purple',\n",
    "    'orange', 'brown', 'pink', 'black', 'white',\n",
    "    'gray', 'cyan', 'magenta', 'violet', 'indigo'\n",
    "]\n",
    "\n",
    "\n",
    "DATA_DIR = Path('../data')\n",
    "EXPERIMENT_DIR = DATA_DIR / EXPERIMENT_NAME\n",
    "EXPERIMENT_DIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "\n",
    "def bootstrap() -> None:\n",
    "    logging.basicConfig(format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "    np.random.seed(RANDOM_SEED)\n",
    "\n",
    "\n",
    "bootstrap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT_TEMPLATE = \"\"\"\\\n",
    "You are a bandit algorithm in a room with {{n_arms}} buttons labeled {{colors|join(\", \")}}. \\\n",
    "Each button is associated with a Bernoulli distribution with a fixed but unknown mean; the means \\\n",
    "for the buttons could be different. For each button, when you press it, you will get a reward \\\n",
    "that is sampled from the button's associated distribution. You have {{n_trials}} time steps and, on each \\\n",
    "time step, you can choose any button and receive the reward. Your goal is to maximize the total \\\n",
    "reward over the {{n_trials}} time steps.\n",
    "\n",
    "At each time step, I will show you a summary of your past choices and rewards. Then you must \\\n",
    "make the next choice, which must be exactly one of {{colors|join(\", \")}}. Let's think \\\n",
    "step by step to make sure we make a good choice. You must provide your final answer within the \\\n",
    "tags <Answer>COLOR</Answer> where COLOR is one of {{colors|join(\", \")}}.\n",
    "\"\"\"\n",
    "SYSTEM_PROMPT_TEMPLATE = Template(SYSTEM_PROMPT_TEMPLATE)\n",
    "\n",
    "\n",
    "USER_PROMPT_TEMLATE = \"\"\"\\\n",
    "So far you have played {{n_trials}} times with your past choices and rewards summarized\n",
    "as follows:\n",
    "- blue button: pressed {{blue_n_occur}} times {%- if blue_n_occur != 0 %} with average reward \\\n",
    "{{blue_avg_reward}}{% endif %}\n",
    "- green button: pressed {{green_n_occur}} times {%- if green_n_occur != 0 %} with average reward \\\n",
    "{{green_avg_reward}}{% endif %}\n",
    "- red button: pressed {{red_n_occur}} times {%- if red_n_occur != 0 %} with average reward \\\n",
    "{{red_avg_reward}}{% endif %}\n",
    "- yellow button: pressed {{yellow_n_occur}} times {%- if yellow_n_occur != 0 %} with average \\\n",
    "reward {{yellow_avg_reward}}{% endif %}\n",
    "- purple button: pressed {{purple_n_occur}} times {%- if purple_n_occur != 0 %} with average \\\n",
    "reward {{purple_avg_reward}}{% endif %}\n",
    "\n",
    "Which button will you choose next? Remember, YOU MUST provide your final answer within the tags \\\n",
    "<Answer>COLOR</Answer> where COLOR is one of {{colors|join(\", \")}}. Let's think step \\\n",
    "by step to make sure we make a good choice.\n",
    "\"\"\"\n",
    "USER_PROMPT_TEMLATE = Template(USER_PROMPT_TEMLATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "So far you have played 10 times with your past choices and rewards summarized\n",
      "as follows:\n",
      "- blue button: pressed 4 times with average reward 0.4\n",
      "- green button: pressed 0 times\n",
      "- red button: pressed 3 times with average reward 0.1\n",
      "- yellow button: pressed 0 times\n",
      "- purple button: pressed 3 times with average reward 0.2\n",
      "\n",
      "Which button will you choose next? Remember, YOU MUST provide your final answer within the tags <Answer>COLOR</Answer> where COLOR is one of . Let's think step by step to make sure we make a good choice.\n"
     ]
    }
   ],
   "source": [
    "# Rendering example\n",
    "example_prompt_inputs = {\n",
    "    'n_trials': 10,\n",
    "    'blue_n_occur': 4,\n",
    "    'blue_avg_reward': 0.4,\n",
    "    'green_n_occur': 0,\n",
    "    'green_avg_reward': 0,\n",
    "    'red_n_occur': 3,\n",
    "    'red_avg_reward': 0.1,\n",
    "    'yellow_n_occur': 0,\n",
    "    'yellow_avg_reward': 0,\n",
    "    'purple_n_occur': 3,\n",
    "    'purple_avg_reward': 0.2\n",
    "}\n",
    "print(USER_PROMPT_TEMLATE.render(**example_prompt_inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiArmedBandit:\n",
    "    def __init__(self, n_arms: int, delta: float) -> None:\n",
    "        self.n_arms = n_arms\n",
    "        self.delta = delta\n",
    "\n",
    "        means = [0.5 + self.delta / 2] + [0.5 - self.delta / 2] * (self.n_arms - 1)\n",
    "        np.random.shuffle(means)\n",
    "\n",
    "        self.means = means\n",
    "        self.best_arm = np.argmax(means)\n",
    "\n",
    "    def pull(self, arm: int) -> int:\n",
    "        assert 0 <= arm < self.n_arms, f\"Arm {arm} doesn't exist\"\n",
    "\n",
    "        p = self.means[arm]\n",
    "        reward = np.random.binomial(1, p=p)\n",
    "        \n",
    "        return reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_client() -> OpenAI:\n",
    "    client = OpenAI(\n",
    "        base_url=COHERE_BASE_URL,\n",
    "        api_key=COHERE_API_KEY,\n",
    "    )\n",
    "    return client\n",
    "\n",
    "\n",
    "def get_prediction(client: OpenAI, system_prompt: str, user_prompt: str, **kwargs) -> str | None:\n",
    "    messages = [\n",
    "        {\n",
    "            'role': 'system',\n",
    "            'content': system_prompt\n",
    "        },\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': user_prompt\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    prediction = None\n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "            model=MODEL_NAME,\n",
    "            messages=messages,\n",
    "            temperature=TEMPERATURE,\n",
    "            **kwargs\n",
    "        )\n",
    "        prediction = completion.choices[0].message.content\n",
    "    except Exception as _:\n",
    "        raise _\n",
    "        # logging.warning('Request failed')\n",
    " \n",
    "    return prediction\n",
    "\n",
    "\n",
    "def build_prompt_inputs(trial: int, rewards: t.Dict[str, int], occurrences: t.Dict[str, int]) -> t.Dict[str, float]:\n",
    "    def average(key: str):\n",
    "        occ = occurrences[key]\n",
    "        total = rewards[key]\n",
    "        return total / occ if occ != 0 else 0.0\n",
    "    \n",
    "    prompt_inputs = {'n_trials': trial}\n",
    "\n",
    "    colors = occurrences.keys()\n",
    "    for color in colors:\n",
    "        prompt_inputs[f'{color}_n_occur'] = occurrences[color]\n",
    "        prompt_inputs[f'{color}_avg_reward'] = average(color)\n",
    "\n",
    "    return prompt_inputs\n",
    "\n",
    "\n",
    "def extract_arm_color(prediction: str, arm_name_to_idx: t.Dict[str, int]) -> str | None:\n",
    "    names = '|'.join(arm_name_to_idx.keys())\n",
    "    pattern = f'<answer>({names})</answer>'\n",
    "    match = re.search(pattern, prediction.lower())\n",
    "\n",
    "    color = None\n",
    "    if match:\n",
    "        color = match.group(1)\n",
    "\n",
    "    return color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(n_trials: int,\n",
    "                   n_arms: int,\n",
    "                   delta: float,\n",
    "                   system_prompt_template: Template,\n",
    "                   user_prompt_template: Template) -> pd.DataFrame:\n",
    "    assert n_arms <= len(COLORS)\n",
    "    \n",
    "    arm_name_to_idx = {name: idx for name, idx in zip(COLORS, range(n_arms))}\n",
    "    arm_idx_to_name = {idx: name for name, idx in arm_name_to_idx.items()}\n",
    "\n",
    "    colors = arm_name_to_idx.keys()\n",
    "    \n",
    "    client = create_client()\n",
    "    bandit = MultiArmedBandit(n_arms=n_arms, delta=delta)\n",
    "\n",
    "    rewards = {k: 0 for k in arm_name_to_idx.keys()}\n",
    "    occurrences = {k: 0 for k in arm_name_to_idx.keys()}\n",
    "\n",
    "    stats = []\n",
    "    for trial in range(n_trials):\n",
    "        system_prompt = system_prompt_template.render({'n_arms': n_arms, 'n_trials': n_trials, 'colors': colors})\n",
    "\n",
    "        user_prompt_inputs = build_prompt_inputs(trial, rewards, occurrences)\n",
    "        user_prompt_inputs['colors'] = colors\n",
    "        user_prompt = user_prompt_template.render(user_prompt_inputs)\n",
    "        \n",
    "        prediction = get_prediction(client, system_prompt, user_prompt)\n",
    "\n",
    "        arm_name = None\n",
    "        arm_idx = None\n",
    "        reward = None\n",
    "        if prediction is not None:\n",
    "            arm_name = extract_arm_color(prediction, arm_name_to_idx)\n",
    "\n",
    "            arm_idx = None\n",
    "            reward = None\n",
    "            if arm_name is not None:\n",
    "                arm_idx = arm_name_to_idx[arm_name]\n",
    "\n",
    "                reward = bandit.pull(arm_idx)\n",
    "\n",
    "                occurrences[arm_name] += 1\n",
    "                rewards[arm_name] += reward\n",
    "        \n",
    "        cumulative_reward = sum(rewards.values())\n",
    "        cumulative_reward_per_arm = {f'cumulative_reward_{k}': v for k, v in rewards.items()}\n",
    "        cumulative_occurrences_per_arm = {f'cumulative_occurrence_{k}': v for k, v in occurrences.items()}\n",
    "\n",
    "        stats.append({\n",
    "            'trial': trial,\n",
    "            'arm_name': arm_name,\n",
    "            'arm_idx': arm_idx,\n",
    "            'reward': reward,\n",
    "            'cumulative_reward': cumulative_reward,\n",
    "            'system_prompt': system_prompt,\n",
    "            'user_prompt': user_prompt,\n",
    "            'raw_prediction': prediction,\n",
    "            'best_arm': arm_idx_to_name[bandit.best_arm],\n",
    "            **cumulative_reward_per_arm,\n",
    "            **cumulative_occurrences_per_arm\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(stats)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dataframe(df: pd.DataFrame, experiment_name: str, model_name: str, n_trials: int, n_arms: int, delta: float):\n",
    "    model_name = model_name.replace('/', '_').replace(':', '_').replace('-', '_')\n",
    "    delta = str(delta).replace('.', '')\n",
    "    version = datetime.now().strftime('%Y%m%d%H%M%S')\n",
    "\n",
    "    filename = f'{experiment_name}_{model_name}_trials-{n_trials}-arms-{n_arms}_delta-{delta}_v{version}.csv'\n",
    "    filepath = EXPERIMENT_DIR / filename\n",
    "\n",
    "    df.to_csv(filepath, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = [(run_id, EXPERIMENT_NAME, N_TRIALS, N_ARMS, DELTA, MODEL_NAME, SYSTEM_PROMPT_TEMPLATE, USER_PROMPT_TEMLATE) for run_id in range(N_EXPERIMENT_RUNS)]\n",
    "\n",
    "def run_experiment_and_save_results(run_id: str,\n",
    "                                    experiment_name: str,\n",
    "                                    n_trials: int,\n",
    "                                    n_arms: int,\n",
    "                                    delta: float,\n",
    "                                    model_name: str,\n",
    "                                    system_prompt_template: Template,\n",
    "                                    user_prompt_template: Template) -> None:\n",
    "    df = run_experiment(n_trials=n_trials, n_arms=n_arms, delta=delta, system_prompt_template=system_prompt_template, user_prompt_template=user_prompt_template)\n",
    "    df['run_id'] = run_id\n",
    "\n",
    "    save_dataframe(df=df, experiment_name=experiment_name, model_name=model_name, n_trials=n_trials, n_arms=n_arms, delta=delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5605c63ae65a4b90ae0b54db9616de45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running experiments:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with ThreadPoolExecutor(max_workers=N_WORKERS) as executor:\n",
    "    futures = [executor.submit(run_experiment_and_save_results, *config) for config in configs]\n",
    "\n",
    "    for future in tqdm(as_completed(futures), total=len(futures), desc=\"Running experiments\"):\n",
    "            try:\n",
    "                future.result()  # Retrieve result to catch exceptions\n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred during experiment execution: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
